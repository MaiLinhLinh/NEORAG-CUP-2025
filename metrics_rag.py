import pandas as pd
import time
import os
from collections import defaultdict
from functools import lru_cache
from google import genai
from google.genai import types

@lru_cache(maxsize=1)
def _get_reranker():
    from rerank import Reranker           # import trong hÃ m Ä‘á»ƒ trÃ¡nh import vÃ²ng & náº·ng
    return Reranker()                     # chá»‰ táº¡o 1 láº§n duy nháº¥t

@lru_cache(maxsize=1) 
def _get_llm(): 
    import os 
    from google import genai
    client = genai.Client(api_key=os.environ["GEMINI_API_KEY"])
    return client


reranker = _get_reranker()           # láº¥y singleton; láº§n Ä‘áº§u má»›i khá»Ÿi táº¡o


def hit_k(file_clb_proptit, file_train_data_proptit, embedding, vector_db, k=5):
    
    print("Äang cháº¡y hit_k")
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train_data_proptit)

    hits = 0
    total_queries = len(df_train)

    initial_top_n = max(2*k, k)
    for index, row in df_train.iterrows():
        query = row['Query']
        ground_truth_doc = row['Ground truth document']
        # TODO: Náº¿u cÃ¡c em dÃ¹ng Text2SQL RAG hay cÃ¡c phÆ°Æ¡ng phÃ¡p sá»­ dá»¥ng ngÃ´n ngá»¯ truy váº¥n, cÃ³ thá»ƒ bá» qua biáº¿n user_embedding
        # CÃ¡c em cÃ³ thá»ƒ dÃ¹ng cÃ¡c kÄ© thuáº­t Ä‘á»ƒ viáº¿t láº¡i cÃ¢u query, Reranking, ... á»Ÿ Ä‘oáº¡n nÃ y.
        # Embedding cÃ¢u query

      

        user_embedding = embedding.encode(query)
        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan Ä‘áº¿n cÃ¢u query trong cÆ¡ sá»Ÿ dá»¯ liá»‡u

        # retrieve rá»™ng trÆ°á»›c rá»“i rerank láº¥y top k
        results = vector_db.query("information", user_embedding, limit = initial_top_n)
        # rerank
        #results = vector_db.query("information", user_embedding, limit = k)
        '''
        cnt = 0
        print("Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
        
        for result in results:
            print (f"VÄƒn báº£n sá»‘ {cnt+1}:")
            print (f"Title: {result['title']}")
            print (f"Information: {result['information']}")
            print ("-" *50)
            cnt += 1
            if cnt == 5:
                break
        '''
        
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)
        

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)
        
        reranked_results = reranked_results[:k]
        '''
        #in ket qua sau reranking
        print("\n Káº¿t quáº£ sau rerank")
        
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
            print("-" *50)
        '''
        # Láº¥y danh sÃ¡ch tÃ i liá»‡u Ä‘Æ°á»£c truy suáº¥t
        retrieved_docs = [int(reranked_result['title'].split()[-1]) for reranked_result in reranked_results if 'title' in reranked_result]
        ground_truth_docs =  []
        if type(ground_truth_doc) is str:
            for doc in ground_truth_doc.split(","):
                ground_truth_docs.append(int(doc))
        else:
            ground_truth_docs.append(int(ground_truth_doc))
        if any(doc in retrieved_docs for doc in ground_truth_docs):
            hits += 1
    return hits / total_queries if total_queries > 0 else 0


# HÃ m recall@k
def recall_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    print("Äang cháº¡y recall_k")
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)
    reranker = _get_reranker()
    
    ans = 0
    initial_top_n = max(2*k, k)
    for index, row in df_train.iterrows():
        hits = 0
        query = row['Query']
        ground_truth_doc = row['Ground truth document']
        # TODO: Náº¿u cÃ¡c em dÃ¹ng Text2SQL RAG hay cÃ¡c phÆ°Æ¡ng phÃ¡p sá»­ dá»¥ng ngÃ´n ngá»¯ truy váº¥n, cÃ³ thá»ƒ bá» qua biáº¿n user_embedding
        # CÃ¡c em cÃ³ thá»ƒ dÃ¹ng cÃ¡c kÄ© thuáº­t Ä‘á»ƒ viáº¿t láº¡i cÃ¢u query, Reranking, ... á»Ÿ Ä‘oáº¡n nÃ y.
        # Embedding cÃ¢u query
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information", user_embedding, limit = initial_top_n)
        #print (f"Results size: {len(results)}")
        #Rerank
        
        
        #print("ğŸ“„ Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
        
        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)


        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)
        
        reranked_results = reranked_results[:k]
        '''
        #in ket qua sau reranking

        # In káº¿t quáº£ sau reranking
        #print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")

        
        # Láº¥y danh sÃ¡ch tÃ i liá»‡u Ä‘Æ°á»£c truy suáº¥t
        retrieved_docs = [int(reranked_result['title'].split()[-1]) for reranked_result in results if 'title' in reranked_result]
        
        ground_truth_docs =  []
        if type(ground_truth_doc) is str:
            for doc in ground_truth_doc.split(","):
                ground_truth_docs.append(int(doc))
        else:
            ground_truth_docs.append(int(ground_truth_doc))
        if any(doc in retrieved_docs for doc in ground_truth_docs):
            hits = len([doc for doc in ground_truth_docs if doc in retrieved_docs])
        ans += hits / len(ground_truth_docs) 
    return ans / len(df_train)


# HÃ m precision@k
def precision_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    print("Äang cháº¡y precision_k")
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    ans = 0
    initial_top_n = max(5*k, k)
    for index, row in df_train.iterrows():
        hits = 0
        query = row['Query']
        ground_truth_doc = row['Ground truth document']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information",user_embedding,limit= k)
        
        # Rerank
        '''
        print("Káº¿t quáº£ trÆ°á»›c rerank:")

        cnt = 0
        for result in results:
            print (f"VÄƒn báº£n sá»‘: {cnt+1}")
            print(f"Title: {result['title']}")
            print (f"Information: {result['information']}")
            print("-" *50)
            cnt+=1
            if cnt == 5:
                break
        '''
        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)
        
        reranked_results = reranked_results[:k]
        '''
        # In káº¿t quáº£ sau reranking
        '''
        dem = 0
        print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
            print("-" *50)
            dem+= 1
            if dem == 5:
                break
        '''
        # Láº¥y danh sÃ¡ch tÃ i liá»‡u Ä‘Æ°á»£c truy suáº¥t
        retrieved_docs = [int(reranked_result['title'].split()[-1]) for reranked_result in results if 'title' in reranked_result]
        
        # print(f"Retrieved documents: {retrieved_docs}")
        ground_truth_docs =  []
        if type(ground_truth_doc) is str:
            for doc in ground_truth_doc.split(","):
                ground_truth_docs.append(int(doc))
        else:
            ground_truth_docs.append(int(ground_truth_doc))
        # print("Ground truth documents:", ground_truth_docs)
        # Kiá»ƒm tra xem cÃ³ Ã­t nháº¥t má»™t tÃ i liá»‡u Ä‘Ãºng trong káº¿t quáº£ tÃ¬m kiáº¿m
        if any(doc in retrieved_docs for doc in ground_truth_docs):
            hits = len([doc for doc in retrieved_docs if doc in ground_truth_docs])
        ans += hits / k 
        # print("Hits / k for this query:", hits / k)
    return ans / len(df_train)


# HÃ m f1@k
def f1_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    print("Äang cháº¡y f1_k")
    precision = precision_k(file_clb_proptit, file_train, embedding, vector_db, k)
    recall = recall_k(file_clb_proptit, file_train, embedding, vector_db, k)
    if precision + recall == 0:
        return 0
    return 2 * (precision * recall) / (precision + recall)

# HÃ m MAP@k

def map_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    print("Äang cháº¡y map_k")
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    total_map = 0
    initial_top_n = max(5*k, k)
    for index, row in df_train.iterrows():
        hits = 0
        ap = 0
        query = row['Query']
        ground_truth_doc = row['Ground truth document']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information",user_embedding,limit= k)

        # Rerank
        '''
        print("Káº¿t quáº£ trÆ°á»›c rerank:")

        cnt = 0
        for result in results:
            print (f"VÄƒn báº£n sá»‘: {cnt+1}")
            print(f"Title: {result['title']}")
            print (f"Information: {result['information']}")
            cnt+=1
            if cnt == 5:
                break
        print("-" *50)
        '''
        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)
        
        reranked_results = reranked_results[:k]
        '''

        # In káº¿t quáº£ sau reranking
        '''
        print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
        print("-" *50)
        '''
        # Láº¥y danh sÃ¡ch tÃ i liá»‡u Ä‘Æ°á»£c truy suáº¥t
        retrieved_docs = [int(reranked_result['title'].split()[-1]) for reranked_result in results if 'title' in reranked_result]
        # print(f"Retrieved documents: {retrieved_docs}")
        ground_truth_docs =  []
        if type(ground_truth_doc) is str:
            for doc in ground_truth_doc.split(","):
                ground_truth_docs.append(int(doc))
        else:
            ground_truth_docs.append(int(ground_truth_doc))
        # print("Ground truth documents:", ground_truth_docs)
        
        # TÃ­nh MAP cho 1 truy váº¥n
        for i, doc in enumerate(retrieved_docs):
            if doc in ground_truth_docs:
                hits += 1
                ap += hits / (i + 1)
        if hits > 0:
            ap /= hits
        # print(f"Average Precision for this query: {ap}")
        total_map += ap 
    return total_map / len(df_train)

# HÃ m MRR@k
def mrr_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    print("Äang cháº¡y mrr_k")
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    total_mrr = 0
    initial_top_n = max(10*k,k)
    for index, row in df_train.iterrows():
        query = row['Query']
        ground_truth_doc = row['Ground truth document']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)


        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information",user_embedding,limit= k)

        # Rerank
        '''
        print("Káº¿t quáº£ trÆ°á»›c rerank:")

        cnt = 0
        for result in results:
            print (f"VÄƒn báº£n sá»‘: {cnt+1}")
            print(f"Title: {result['title']}")
            print (f"Information: {result['information']}")
            cnt+=1
            if cnt == 5:
                break
        print("-" *50)
        '''

        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)
        
        reranked_results = reranked_results[:k]
        '''
        # In káº¿t quáº£ sau reranking
        '''
        print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
        print("-" *50)
        '''
        # Láº¥y danh sÃ¡ch tÃ i liá»‡u Ä‘Æ°á»£c truy suáº¥t
        retrieved_docs = [int(reranked_result['title'].split()[-1]) for reranked_result in results if 'title' in reranked_result]
        # print(f"Retrieved documents: {retrieved_docs}")
        ground_truth_docs =  []
        if type(ground_truth_doc) is str:
            for doc in ground_truth_doc.split(","):
                ground_truth_docs.append(int(doc))
        else:
            ground_truth_docs.append(int(ground_truth_doc))
        # print("Ground truth documents:", ground_truth_docs)
        
        # TÃ­nh MRR cho 1 truy váº¥n
        for i, doc in enumerate(retrieved_docs):
            if doc in ground_truth_docs:
                total_mrr += 1 / (i + 1)
                break
    return total_mrr / len(df_train) if len(df_train) > 0 else 0

# HÃ m NDCG@k
import numpy as np
def dcg_at_k(relevances, k):
    relevances = np.array(relevances)[:k]
    return np.sum((2**relevances - 1) / np.log2(np.arange(2, len(relevances) + 2)))

def ndcg_at_k(relevances, k):
    dcg_max = dcg_at_k(sorted(relevances, reverse=True), k)
    if dcg_max == 0:
        return 0.0
    return dcg_at_k(relevances, k) / dcg_max

def similarity(embedding1, embedding2):
    # Giáº£ sá»­ ta cÃ³ má»™t hÃ m Ä‘á»ƒ tÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a hai embedding
    # á» Ä‘Ã¢y ta sáº½ sá»­ dá»¥ng cosine similarity, chuáº©n hÃ³a Ä‘á»ƒ score nÆ°á»›c vá» khoáº£ng [0, 1]
    dot_product = np.dot(embedding1, embedding2)
    norm1 = np.linalg.norm(embedding1)
    norm2 = np.linalg.norm(embedding2)
    if norm1 == 0 or norm2 == 0:
        return 0.0
    cos_sim = dot_product / (norm1 * norm2)
    return (cos_sim + 1) / 2


def ndcg_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    print("Äang cháº¡y ndcg_k")
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    total_ndcg = 0
    initial_top_n = max(10*k,k)
    for index, row in df_train.iterrows():
        query = row['Query']
        ground_truth_doc = row['Ground truth document']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information",user_embedding,limit= k)

        # Rerank
        '''
        print("Káº¿t quáº£ trÆ°á»›c rerank:")

        cnt = 0
        for result in results:
            print (f"VÄƒn báº£n sá»‘: {cnt+1}")
            print(f"Title: {result['title']}")
            print (f"Information: {result['information']}")
            cnt+=1
            if cnt == 5:
                break
        print("-" *50)
        '''

        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)
        
        reranked_results = reranked_results[:k]
        '''
        # In káº¿t quáº£ sau reranking
        '''
        print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
        print("-" *50)
        '''
        # Láº¥y danh sÃ¡ch tÃ i liá»‡u Ä‘Æ°á»£c truy suáº¥t
        retrieved_docs = [int(reranked_result['title'].split()[-1]) for reranked_result in results if 'title' in reranked_result]

        ground_truth_docs = []
        if type(ground_truth_doc) is str:
            for doc in ground_truth_doc.split(","):
                ground_truth_docs.append(int(doc))
        else:
            ground_truth_docs.append(int(ground_truth_doc))


        # Náº¿u Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng > 0.9 thÃ¬ gÃ¡n 3, náº¿u > 0.7 thÃ¬ gÃ¡n 2, náº¿u > 0.5 thÃ¬ gÃ¡n 1, cÃ²n láº¡i thÃ¬ gÃ¡n 0 
        relevances = []
        for doc in retrieved_docs:
            if doc in ground_truth_docs:
                # Giáº£ sá»­ ta cÃ³ má»™t hÃ m Ä‘á»ƒ tÃ­nh Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a cÃ¢u há»i vÃ  tÃ i liá»‡u, doc lÃ  sá»‘ thá»© tá»± cá»§a tÃ i liá»‡u trong file CLB_PROPTIT.csv
                similarity_score = similarity(user_embedding, embedding.encode(df_clb.loc[doc - 1, 'VÄƒn báº£n']))
                if similarity_score > 0.9:
                    relevances.append(3)
                elif similarity_score > 0.7:
                    relevances.append(2)
                elif similarity_score > 0.5:
                    relevances.append(1)
                else:
                    relevances.append(0)
            else:
                relevances.append(0)
        ndcg = ndcg_at_k(relevances, k)
        # print(f"NDCG for this query: {ndcg}")
        total_ndcg += ndcg

    return total_ndcg / len(df_train) if len(df_train) > 0 else 0

# HÃ m Context Precision@k (LLM Judged)

def context_precision_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    print("Äang cháº¡y context_precision_k")
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    total_precision = 0
    initial_top_n = max(10 *k,k)
    for index, row in df_train.iterrows():
        # TODO: Táº¡o ra LLM Answer, cÃ¡c em hÃ£y tá»± viáº¿t pháº§n system prompt
        messages = [
            {
                "role": "system",
                "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn cung cáº¥p thÃ´ng tin vá» CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT.
                Báº¡n sáº½ nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u ngá»¯ cáº£nh (context) tá»« má»™t há»‡ thá»‘ng Retrieval-Augmented Generation (RAG) chá»©a cÃ¡c thÃ´ng tin chÃ­nh xÃ¡c vá» CLB.

                NguyÃªn táº¯c tráº£ lá»i:
                1. Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« context Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ tráº£ lá»i. Context sáº½ Ä‘Æ°á»£c cung cáº¥p á»Ÿ Ä‘áº§u má»—i query cá»§a ngÆ°á»i dÃ¹ng. CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng náº±m á»Ÿ Ä‘áº§u. 
                2. Náº¿u ngÆ°á»i dÃ¹ng há»i cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n CLB ProPTIT, hÃ£y tráº£ lá»i nhÆ° bÃ¬nh thÆ°á»ng, nhÆ°ng khÃ´ng sá»­ dá»¥ng thÃ´ng tin tá»« context.
                3. TrÃ¬nh bÃ y cÃ¢u tráº£ lá»i rÃµ rÃ ng, dá»… hiá»ƒu. CÃ³ thá»ƒ sá»­ dá»¥ng emoij icon khi cáº§n.
                4. Tuyá»‡t Ä‘á»‘i khÃ´ng suy Ä‘oÃ¡n hoáº·c bá»‹a thÃ´ng tin.
                5. Giá»¯ phong cÃ¡ch tráº£ lá»i thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  nháº¥t quÃ¡n.
                6. Trong context cÃ³ thá»ƒ chá»©a nhiá»u thÃ´ng tin khÃ¡c nhau, hÃ£y táº­p trung vÃ o cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c nháº¥t.

                Nhiá»‡m vá»¥ cá»§a báº¡n:
                - Tráº£ lá»i cÃ¡c cÃ¢u há»i vá» CLB Láº­p trÃ¬nh ProPTIT: lá»‹ch sá»­, thÃ nh viÃªn, hoáº¡t Ä‘á»™ng, sá»± kiá»‡n, dá»± Ã¡n, ná»™i quy, thÃ nh viÃªn tiÃªu biá»ƒu, vÃ  cÃ¡c thÃ´ng tin liÃªn quan khÃ¡c.
                """
            }
        ]
        hits = 0
        query = row['Query']
        ground_truth_doc = row['Ground truth document']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information",user_embedding,limit= k)
        
        # TODO: viáº¿t cÃ¢u query cá»§a ngÆ°á»i dÃ¹ng (bao gá»“m document retrieval vÃ  cÃ¢u query)
        
        # rerank
        cnt = 0
        #print("ğŸ“„ Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
        '''
        for result in results:
            print(f"VÄƒn báº£n sá»‘ {cnt + 1}:")
            print(f"Title: {result['title']}")
            print(f"Information: {result['information']}")
            print("-" * 50)
            cnt += 1
            if(cnt == 5):
                break
        '''
        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)

        reranked_results = reranked_results[:k]
        reranker_passages = reranker_passages[:k]
        '''
        # In káº¿t quáº£ sau reranking
        #print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        '''
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
        print("-" *50)
        '''
        #GhÃ©p cÃ¡c Ä‘oáº¡n tÃ¬m Ä‘Æ°á»£c thÃ nh má»™t khá»‘i 'context' vÄƒn báº£n pháº³ng
        #context = "\n".join(reranker_passages)
        context = "\n".join(result["information"] for result in results)

        new_context =  f"\nCÃ¢u há»i: {query}\n" + f"\nThÃ´ng tin liÃªn quan:\n{context}"
        
        

        # ThÃªm context vÃ o messages
        
        messages.append({
            "role": "user",
            "content": new_context
        })
        
        # Gá»i  API Ä‘á»ƒ láº¥y cÃ¢u tráº£ lá»i
        response = embedding.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages
            )
        reply = response.choices[0].message.content.strip()
        
        #print("In káº¿t quáº£ LLM reply:")
        #print(reply)
        #print("-" *50)

        # Äáº©y cÃ¡c Ä‘oáº¡n vÄƒn Ä‘Æ°á»£c retrieved vÃ  cÃ¢u tráº£ lá»i cá»§a LLM vÃ o má»™t LLM Judged context vá»›i prompt system
        # LLM Judged context
        for result in results:
            # NOTE: CÃ¡c em cÃ³ thá»ƒ chá»‰nh messages_judged náº¿u muá»‘n
            messages_judged = [
                {
                    "role": "system",
                    "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c cÃ¢u tráº£ lá»i dá»±a trÃªn ngá»¯ cáº£nh Ä‘Æ°á»£c cung cáº¥p. Báº¡n sáº½ Ä‘Æ°á»£c cung cáº¥p má»™t ngá»¯ cáº£nh, má»™t cÃ¢u há»i vÃ  má»™t cÃ¢u tráº£ lá»i tá»« má»™t mÃ´ hÃ¬nh AI. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘Ã¡nh giÃ¡ cÃ¢u tráº£ lá»i dá»±a trÃªn ngá»¯ cáº£nh vÃ  cÃ¢u há»i. Náº¿u ngá»¯ cáº£nh vÃ  cÃ¢u há»i cung cáº¥p Ä‘á»§ thÃ´ng tin hoáº·c chá»‰ cáº§n má»™t pháº§n thÃ´ng tin Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i, hÃ£y Ä‘Ã¡nh giÃ¡ cÃ¢u tráº£ lá»i lÃ  1. Náº¿u khÃ´ng, hÃ£y Ä‘Ã¡nh giÃ¡ lÃ  0. HÃ£y Ä‘á»c tháº­t kÄ© ngá»¯ cáº£nh, chá»‰ cáº§n ngá»¯ cáº£nh cÃ³ má»™t pháº§n thÃ´ng tin Ä‘á»ƒ tráº£ lá»i cho má»™t pháº§n cá»§a cÃ¢u há»i thÃ¬ cÅ©ng Ä‘Ã¡nh giÃ¡ lÃ  1. Náº¿u ngá»¯ cáº£nh khÃ´ng liÃªn quan gÃ¬ Ä‘áº¿n cÃ¢u há»i, hÃ£y Ä‘Ã¡nh giÃ¡ lÃ  0. LÆ¯U Ã: Chá»‰ tráº£ lá»i 1 hoáº·c 0, khÃ´ng giáº£i thÃ­ch gÃ¬ thÃªm."""
                }
            ]
            # TODO: "content" sáº½ lÆ°u ngá»¯ cáº£nh, cÃ¢u há»i, cÃ¢u tráº£ lá»i
            messages_judged.append({
                "role": "user",
                "content": f"Ngá»¯ cáº£nh: {result['information']}\n\nCÃ¢u há»i: {query}\n\nCÃ¢u tráº£ lá»i: {reply}"
            })
            # Gá»i API Ä‘áº¿n LLM Judged
            

            # Gá»i OpenAI API Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ cÃ¢u tráº£ lá»i
            judged_response = embedding.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages_judged
            )
            judged_reply = judged_response.choices[0].message.content.strip()
            if judged_reply == "1":
                hits += 1
            #print("LLM Ä‘Ã¡nh giÃ¡ xong 1 káº¿t quáº£")
            time.sleep(3)
        #print("-" *50)
        precision = hits / k if k > 0 else 0
        total_precision += precision
        time.sleep(5)
    return total_precision / len(df_train) if len(df_train) > 0 else 0


# HÃ m Context Recall@k (LLM Judged)
def context_recall_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    print("Äang cháº¡y hÃ m context_recall_k")
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    total_recall = 0
    initial_top_n = max(10*k,k)
    for index, row in df_train.iterrows():
        hits = 0
        query = row['Query']
        ground_truth_doc = row['Ground truth document']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information",user_embedding,limit= k)

        # rerank
        cnt = 0
        #print("ğŸ“„ Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
        '''
        for result in results:
            print(f"VÄƒn báº£n sá»‘ {cnt + 1}:")
            print(f"Title: {result['title']}")
            print(f"Information: {result['information']}")
            print("-" * 50)
            cnt += 1
            if(cnt == 5):
                break
        '''
        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)

        reranked_results = reranked_results[:k]
        
        '''
        # In káº¿t quáº£ sau reranking

        #print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        
        #print("ÄÃ£ tÃ¬m kiáº¿m Ä‘Æ°á»£c thÃ´ng tin cho cÃ¢u há»i")

        reply = row['Ground truth answer']
        

        # NOTE: CÃ¡c em cÃ³ thá»ƒ thay Ä‘á»•i messages_judged náº¿u muá»‘n 
        for result in results:
            messages_judged = [
                {
                    "role": "system",
                    "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cá»§a cÃ¡c cÃ¢u tráº£ lá»i dá»±a trÃªn ngá»¯ cáº£nh Ä‘Æ°á»£c cung cáº¥p. Báº¡n sáº½ Ä‘Æ°á»£c cung cáº¥p má»™t ngá»¯ cáº£nh, má»™t cÃ¢u há»i vÃ  má»™t cÃ¢u tráº£ lá»i Ä‘Ã£ Ä‘Æ°á»£c chuyÃªn gia tráº£ lá»i cho cÃ¢u há»i (Ä‘Ã¢y lÃ  cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c). Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘Ã¡nh giÃ¡ ngá»¯ cáº£nh dá»±a trÃªn cÃ¢u há»i vÃ  cÃ¢u tráº£ lá»i. Náº¿u ngá»¯ cáº£nh vÃ  cÃ¢u há»i cung cáº¥p Ä‘á»§ thÃ´ng tin hoáº·c chá»‰ cáº§n má»™t pháº§n thÃ´ng tin Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i, hÃ£y Ä‘Ã¡nh giÃ¡ ngá»¯ cáº£nh lÃ  1. Náº¿u khÃ´ng, hÃ£y Ä‘Ã¡nh giÃ¡ lÃ  0. HÃ£y Ä‘á»c tháº­t kÄ© ngá»¯ cáº£nh, chá»‰ cáº§n ngá»¯ cáº£nh cÃ³ má»™t pháº§n thÃ´ng tin Ä‘á»ƒ tráº£ lá»i cho má»™t pháº§n cá»§a cÃ¢u há»i thÃ¬ cÅ©ng Ä‘Ã¡nh giÃ¡ lÃ  1. Náº¿u ngá»¯ cáº£nh khÃ´ng liÃªn quan gÃ¬ Ä‘áº¿n cÃ¢u há»i, hÃ£y Ä‘Ã¡nh giÃ¡ lÃ  0. LÆ¯U Ã: Chá»‰ tráº£ lá»i 1 hoáº·c 0, khÃ´ng giáº£i thÃ­ch gÃ¬ thÃªm."""
                }
            ]
            messages_judged.append({
                "role": "user",
                "content":f"Ngá»¯ cáº£nh: {result['information']}\n\nCÃ¢u há»i: {query}\n\nCÃ¢u tráº£ lá»i: {reply}"
            })

            judged_response = embedding.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages_judged
            )
            judged_reply = judged_response.choices[0].message.content.strip()
            if judged_reply == "1":
                hits += 1
            time.sleep(3)
            #print("LLM Ä‘Ã£ Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c 1 query")
        recall = hits / k if k > 0 else 0
        total_recall += recall
        time.sleep(5)
    return total_recall / len(df_train) if len(df_train) > 0 else 0

# HÃ m Context Entities Recall@k (LLM Judged)
def context_entities_recall_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    print("Äang cháº¡y context_entities_recall_k")
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    total_recall = 0
    initial_top_n = max(10*k, k)
    for index, row in df_train.iterrows():
        hits = 0
        query = row['Query']
        ground_truth_doc = row['Ground truth document']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        reply = row['Ground truth answer']
        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information",user_embedding,limit= k)

        # rerank
        cnt = 0
        #print("ğŸ“„ Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
        '''
        for result in results:
            print(f"VÄƒn báº£n sá»‘ {cnt + 1}:")
            print(f"Title: {result['title']}")
            print(f"Information: {result['information']}")
            print("-" * 50)
            cnt += 1
            if(cnt == 5):
                break
        '''
        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)

        reranked_results = reranked_results[:k]
        '''
        # In káº¿t quáº£ sau reranking
        #print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        
        # TrÃ­ch xuáº¥t cÃ¡c thá»±c thá»ƒ tá»« Ground truth answer báº±ng LLM
        # NOTE: CÃ¡c em cÃ³ thá»ƒ thay Ä‘á»•i messages_entities náº¿u muá»‘n
        messages_entities = [
            {
                "role": "system",
                "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn trÃ­ch xuáº¥t cÃ¡c thá»±c thá»ƒ tá»« cÃ¢u tráº£ lá»i. Báº¡n sáº½ Ä‘Æ°á»£c cung cáº¥p má»™t cÃ¢u tráº£ lá»i vÃ  nhiá»‡m vá»¥ cá»§a báº¡n lÃ  trÃ­ch xuáº¥t cÃ¡c thá»±c thá»ƒ tá»« cÃ¢u tráº£ lá»i Ä‘Ã³. CÃ¡c thá»±c thá»ƒ cÃ³ thá»ƒ lÃ  tÃªn ngÆ°á»i, Ä‘á»‹a Ä‘iá»ƒm, tá»• chá»©c, sá»± kiá»‡n, v.v. HÃ£y tráº£ lá»i dÆ°á»›i dáº¡ng má»™t danh sÃ¡ch cÃ¡c thá»±c thá»ƒ.
                VÃ­ dá»¥:
                CÃ¢u tráº£ lá»i: Náº¿u báº¡n thuá»™c ngÃ nh khÃ¡c báº¡n váº«n cÃ³ thá»ƒ tham gia CLB chÃºng mÃ¬nh. Náº¿u Ä‘á»‹nh hÆ°á»›ng cá»§a báº¡n hoÃ n toÃ n lÃ  theo CNTT thÃ¬ CLB cháº¯c cháº¯n lÃ  nÆ¡i phÃ¹ há»£p nháº¥t Ä‘á»ƒ cÃ¡c báº¡n phÃ¡t triá»ƒn. Trá»Ÿ ngáº¡i lá»›n nháº¥t sáº½ lÃ  do báº¡n theo má»™t hÆ°á»›ng khÃ¡c ná»¯a nÃªn sáº½ pháº£i táº­p trung vÃ o cáº£ 2 máº£ng nÃªn sáº½ cáº§n cá»‘ gáº¯ng nhiá»u hÆ¡n.
                ["ngÃ nh khÃ¡c", "CLB", "CNTT", "máº£ng]
                CÃ¢u tráº£ lá»i: CÃ¢u láº¡c bá»™ Láº­p TrÃ¬nh PTIT (Programming PTIT), tÃªn viáº¿t táº¯t lÃ  PROPTIT Ä‘Æ°á»£c thÃ nh láº­p ngÃ y 9/10/2011. Vá»›i phÆ°Æ¡ng chÃ¢m hoáº¡t Ä‘á»™ng "Chia sáº» Ä‘á»ƒ cÃ¹ng nhau phÃ¡t triá»ƒn", cÃ¢u láº¡c bá»™ lÃ  nÆ¡i giao lÆ°u, Ä‘Ã o táº¡o cÃ¡c mÃ´n láº­p trÃ¬nh vÃ  cÃ¡c mÃ´n há»c trong trÆ°á»ng, táº¡o Ä‘iá»u kiá»‡n Ä‘á»ƒ sinh viÃªn trong Há»c viá»‡n cÃ³ mÃ´i trÆ°á»ng há»c táº­p nÄƒng Ä‘á»™ng sÃ¡ng táº¡o. Slogan: Láº­p TrÃ¬nh PTIT - Láº­p trÃ¬nh tá»« trÃ¡i tim.
                ["CÃ¢u láº¡c bá»™ Láº­p TrÃ¬nh PTIT (Programming PTIT)", "PROPTIT", "9/10/2011", "Chia sáº» Ä‘á»ƒ cÃ¹ng nhau phÃ¡t triá»ƒn", "sinh viÃªn", "Há»c viá»‡n", "Láº­p TrÃ¬nh PTIT - Láº­p trÃ¬nh tá»« trÃ¡i tim"]"""
            }
        ]
        # NOTE: CÃ¡c em cÃ³ thá»ƒ thay Ä‘á»•i content náº¿u muá»‘n
        messages_entities.append({
            "role": "user",
            "content": f"CÃ¢u tráº£ lá»i: {reply}"
        })
        # Gá»i  API Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c thá»±c thá»ƒ
        entities_response = embedding.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages_entities
        )
        entities = entities_response.choices[0].message.content.strip().split("\n")
        entities = entities[0] # "["ngÃ nh khÃ¡c", "CLB", "CNTT", "máº£ng]" -> ["ngÃ nh khÃ¡c", "CLB", "CNTT", "máº£ng"]
        entities = eval(entities) if entities else []  # Chuyá»ƒn Ä‘á»•i chuá»—i thÃ nh danh sÃ¡ch

        # Sau khi cÃ³ Ä‘Æ°á»£c list thá»±c thá»ƒ tá»« LLM, ta sáº½ Ä‘áº¿m xem cÃ³ bao nhiÃªu thá»±c thá»ƒ trong ngá»¯ cáº£nh Ä‘Æ°á»£c retrieved. Äáº¿m dÆ°á»›i dáº¡ng matching string
        tmp = len(entities)
        for result in results:
            context = result['information']
            for entity in entities:
                if entity.strip() in context:
                    hits += 1
                    entities.remove(entity.strip())
        total_recall += hits / tmp if tmp > 0 else 0
        time.sleep(5)
    return total_recall / len(df_train) if len(df_train) > 0 else 0



# HÃ m tÃ­nh toÃ¡n táº¥t cáº£ metrics liÃªn quan Ä‘áº¿n Retrieval

def calculate_metrics_retrieval(file_clb_proptit, file_train , embedding, vector_db, train):
    # Táº¡o ra 1 báº£ng csv, cá»™t thá»© nháº¥t lÃ  K value, cÃ¡c cá»™t cÃ²n láº¡i lÃ  metrics. Sáº½ cÃ³ 3 hÃ ng tÆ°Æ¡ng trÆ°ng vá»›i k = 3, 5, 7
    k_values = [3, 5, 7]
    metrics = {
        "K": [],
        "hit@k": [],
        "recall@k": [],
        "precision@k": [],
        "f1@k": [],
        "map@k": [],
        "mrr@k": [],
        "ndcg@k": [],
        "context_precision@k": [],
        "context_recall@k": [],
        "context_entities_recall@k": []
    }
    # LÆ°u 2 chá»¯ sá»‘ tháº­p phÃ¢n cho cÃ¡c metrics
    for k in k_values:
        metrics["K"].append(k)
        metrics["hit@k"].append(round(hit_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["recall@k"].append(round(recall_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["precision@k"].append(round(precision_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["f1@k"].append(round(f1_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["map@k"].append(round(map_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["mrr@k"].append(round(mrr_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["ndcg@k"].append(round(ndcg_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["context_precision@k"].append(round(context_precision_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["context_recall@k"].append(round(context_recall_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["context_entities_recall@k"].append(round(context_entities_recall_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
    # Chuyá»ƒn Ä‘á»•i metrics thÃ nh DataFrame
    metrics_df = pd.DataFrame(metrics)
    # LÆ°u DataFrame vÃ o file csv
    if train:
        metrics_df.to_csv("metrics_retrieval_train.csv", index=False)
    else:
        metrics_df.to_csv("metrics_retrieval_test.csv", index=False)
    return metrics_df

# CÃ¡c hÃ m Ä‘Ã¡nh giÃ¡ LLM Answer

# HÃ m String Presence

def string_presence_k(file_clb_proptit, file_train, embedding, vector_db,  k=5):
    
    print("Äang cháº¡y string_presence_k")
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    total_presence = 0
    initial_top_n = max(10*k,k)
    for index, row in df_train.iterrows():
        hits = 0
        query = row['Query']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information", user_embedding, limit= k)
        reply = row['Ground truth answer']
        
        # rerank
        '''
        cnt = 0
        print("ğŸ“„ Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
        for result in results:
            print(f"VÄƒn báº£n sá»‘ {cnt + 1}:")
            print(f"Title: {result['title']}")
            print(f"Information: {result['information']}")
            print("-" * 50)
            cnt += 1
            if(cnt == 5):
                break
        '''
        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)

        reranked_results = reranked_results[:(k+5)]
        '''
        '''
        # In káº¿t quáº£ sau reranking
        print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
        print("-" *50)
        '''
        #GhÃ©p cÃ¡c Ä‘oáº¡n tÃ¬m Ä‘Æ°á»£c thÃ nh má»™t khá»‘i 'context' vÄƒn báº£n pháº³ng
        #context = "\n".join(reranker_passages)
        context = "\n".join(result["information"] for result in results)

        new_context =  f"\nCÃ¢u há»i: {query}\n" + f"\nThÃ´ng tin liÃªn quan:\n{context}"
        messages = [
            {
                "role": "system",
                "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn cung cáº¥p thÃ´ng tin vá» CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT.
                Báº¡n sáº½ nháº­n Ä‘Æ°á»£c cÃ¢u há»i vÃ  dá»¯ liá»‡u ngá»¯ cáº£nh (context) tá»« má»™t há»‡ thá»‘ng Retrieval-Augmented Generation (RAG) chá»©a cÃ¡c thÃ´ng tin chÃ­nh xÃ¡c vá» CLB.

                NguyÃªn táº¯c tráº£ lá»i:
                1. Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« context Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ tráº£ lá»i. Context sáº½ Ä‘Æ°á»£c cung cáº¥p á»Ÿ Ä‘áº§u má»—i query cá»§a ngÆ°á»i dÃ¹ng. CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng náº±m á»Ÿ cuá»‘i. 
                2. Náº¿u ngÆ°á»i dÃ¹ng há»i cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n CLB ProPTIT, hÃ£y tráº£ lá»i nhÆ° bÃ¬nh thÆ°á»ng, nhÆ°ng khÃ´ng sá»­ dá»¥ng thÃ´ng tin tá»« context
                3. TrÃ¬nh bÃ y cÃ¢u tráº£ lá»i rÃµ rÃ ng, dá»… hiá»ƒu. CÃ³ thá»ƒ sá»­ dá»¥ng emoij icon khi cáº§n.
                4. Tuyá»‡t Ä‘á»‘i khÃ´ng suy Ä‘oÃ¡n hoáº·c bá»‹a thÃ´ng tin.
                5. Giá»¯ phong cÃ¡ch tráº£ lá»i thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  nháº¥t quÃ¡n.
                6. Trong context cÃ³ thá»ƒ chá»©a nhiá»u thÃ´ng tin khÃ¡c nhau, hÃ£y táº­p trung vÃ o cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c nháº¥t.

                Nhiá»‡m vá»¥ cá»§a báº¡n:
                - Tráº£ lá»i cÃ¡c cÃ¢u há»i vá» CLB Láº­p trÃ¬nh ProPTIT: lá»‹ch sá»­, thÃ nh viÃªn, hoáº¡t Ä‘á»™ng, sá»± kiá»‡n, dá»± Ã¡n, ná»™i quy, thÃ nh viÃªn tiÃªu biá»ƒu, vÃ  cÃ¡c thÃ´ng tin liÃªn quan khÃ¡c.
                """
            }
        ]
        # ThÃªm context vÃ o messages
        messages.append({
            "role": "user",
            "content": new_context
        })
        # Gá»i  API Ä‘á»ƒ láº¥y cÃ¢u tráº£ lá»i
        response = embedding.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages
            )
        response = response.choices[0].message.content.strip()
        '''
        print("In káº¿t quáº£ LLM reply:")
        print(response)
        print("-" *50)
        '''
        # TrÃ­ch xuáº¥t cÃ¡c thá»±c thá»ƒ tá»« cÃ¢u tráº£ lá»i báº±ng LLM
        # NOTE: CÃ¡c em cÃ³ thá»ƒ thay Ä‘á»•i message_entities náº¿u muá»‘n
        messages_entities = [
            {
                "role": "system",
                "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn trÃ­ch xuáº¥t cÃ¡c thá»±c thá»ƒ tá»« cÃ¢u tráº£ lá»i. Báº¡n sáº½ Ä‘Æ°á»£c cung cáº¥p má»™t cÃ¢u tráº£ lá»i vÃ  nhiá»‡m vá»¥ cá»§a báº¡n lÃ  trÃ­ch xuáº¥t cÃ¡c thá»±c thá»ƒ tá»« cÃ¢u tráº£ lá»i Ä‘Ã³. CÃ¡c thá»±c thá»ƒ cÃ³ thá»ƒ lÃ  tÃªn ngÆ°á»i, Ä‘á»‹a Ä‘iá»ƒm, tá»• chá»©c, sá»± kiá»‡n, v.v. HÃ£y tráº£ lá»i dÆ°á»›i dáº¡ng má»™t danh sÃ¡ch cÃ¡c thá»±c thá»ƒ.
                VÃ­ dá»¥:
                CÃ¢u tráº£ lá»i: Náº¿u báº¡n thuá»™c ngÃ nh khÃ¡c báº¡n váº«n cÃ³ thá»ƒ tham gia CLB chÃºng mÃ¬nh. Náº¿u Ä‘á»‹nh hÆ°á»›ng cá»§a báº¡n hoÃ n toÃ n lÃ  theo CNTT thÃ¬ CLB cháº¯c cháº¯n lÃ  nÆ¡i phÃ¹ há»£p nháº¥t Ä‘á»ƒ cÃ¡c báº¡n phÃ¡t triá»ƒn. Trá»Ÿ ngáº¡i lá»›n nháº¥t sáº½ lÃ  do báº¡n theo má»™t hÆ°á»›ng khÃ¡c ná»¯a nÃªn sáº½ pháº£i táº­p trung vÃ o cáº£ 2 máº£ng nÃªn sáº½ cáº§n cá»‘ gáº¯ng nhiá»u hÆ¡n.
                ["ngÃ nh khÃ¡c", "CLB", "CNTT", "máº£ng]
                CÃ¢u tráº£ lá»i: CÃ¢u láº¡c bá»™ Láº­p TrÃ¬nh PTIT (Programming PTIT), tÃªn viáº¿t táº¯t lÃ  PROPTIT Ä‘Æ°á»£c thÃ nh láº­p ngÃ y 9/10/2011. Vá»›i phÆ°Æ¡ng chÃ¢m hoáº¡t Ä‘á»™ng "Chia sáº» Ä‘á»ƒ cÃ¹ng nhau phÃ¡t triá»ƒn", cÃ¢u láº¡c bá»™ lÃ  nÆ¡i giao lÆ°u, Ä‘Ã o táº¡o cÃ¡c mÃ´n láº­p trÃ¬nh vÃ  cÃ¡c mÃ´n há»c trong trÆ°á»ng, táº¡o Ä‘iá»u kiá»‡n Ä‘á»ƒ sinh viÃªn trong Há»c viá»‡n cÃ³ mÃ´i trÆ°á»ng há»c táº­p nÄƒng Ä‘á»™ng sÃ¡ng táº¡o. Slogan: Láº­p TrÃ¬nh PTIT - Láº­p trÃ¬nh tá»« trÃ¡i tim.
                ["CÃ¢u láº¡c bá»™ Láº­p TrÃ¬nh PTIT (Programming PTIT)", "PROPTIT", "9/10/2011", "Chia sáº» Ä‘á»ƒ cÃ¹ng nhau phÃ¡t triá»ƒn", "sinh viÃªn", "Há»c viá»‡n", "Láº­p TrÃ¬nh PTIT - Láº­p trÃ¬nh tá»« trÃ¡i tim"]"""
            }
        ]
        # Thay Ä‘á»•i content náº¿u muá»‘n
        messages_entities.append({
            "role": "user",
            "content": f"CÃ¢u tráº£ lá»i: {reply}"
        })
        # Gá»i  API Ä‘á»ƒ trÃ­ch xuáº¥t cÃ¡c thá»±c thá»ƒ
        entities_response = embedding.client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages_entities
        )
        entities = entities_response.choices[0].message.content.strip().split("\n")
        entities = entities[0] # "["ngÃ nh khÃ¡c", "CLB", "CNTT", "máº£ng]" -> ["ngÃ nh khÃ¡c", "CLB", "CNTT", "máº£ng"]
        entities = eval(entities) if entities else []  # Chuyá»ƒn Ä‘á»•i chuá»—i thÃ nh danh sÃ¡ch
        for entity in entities:
            if entity.strip() in response:
                hits += 1
                # print(f"Entity '{entity.strip()}' found in response.")
        hits /= len(entities) if len(entities) > 0 else 0
        total_presence += hits
        time.sleep(5)
    return total_presence / len(df_train) if len(df_train) > 0 else 0


 

# HÃ m Rouge-L

from rouge import Rouge
def rouge_l_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    rouge = Rouge()
    total_rouge_l = 0
    initial_top_n = max(10*k,k)
    for index, row in df_train.iterrows():
        query = row['Query']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information", user_embedding, limit=k)
        # rerank
        '''
        cnt = 0
        print("ğŸ“„ Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
        
        for result in results:
            print(f"VÄƒn báº£n sá»‘ {cnt + 1}:")
            print(f"Title: {result['title']}")
            print(f"Information: {result['information']}")
            print("-" * 50)
            cnt += 1
            if(cnt == 5):
                break
        '''
        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)

        reranked_results = reranked_results[:(k+5)]
        '''
        '''
        # In káº¿t quáº£ sau reranking
        print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
            print("-" *50)
        '''
        reply = row['Ground truth answer']
        messages = [
            {
                "role": "system",
                "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn cung cáº¥p thÃ´ng tin vá» CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT.
                Báº¡n sáº½ nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u ngá»¯ cáº£nh (context) tá»« má»™t há»‡ thá»‘ng Retrieval-Augmented Generation (RAG) chá»©a cÃ¡c thÃ´ng tin chÃ­nh xÃ¡c vá» CLB.

                NguyÃªn táº¯c tráº£ lá»i:
                1. Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« context Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ tráº£ lá»i. Context sáº½ Ä‘Æ°á»£c cung cáº¥p á»Ÿ Ä‘áº§u má»—i query cá»§a ngÆ°á»i dÃ¹ng. CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng náº±m á»Ÿ cuá»‘i. 
                2. Náº¿u ngÆ°á»i dÃ¹ng há»i cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n CLB ProPTIT, hÃ£y tráº£ lá»i nhÆ° bÃ¬nh thÆ°á»ng, nhÆ°ng khÃ´ng sá»­ dá»¥ng thÃ´ng tin tá»« context
                3. TrÃ¬nh bÃ y cÃ¢u tráº£ lá»i rÃµ rÃ ng, dá»… hiá»ƒu. CÃ³ thá»ƒ sá»­ dá»¥ng emoij icon khi cáº§n.
                4. Tuyá»‡t Ä‘á»‘i khÃ´ng suy Ä‘oÃ¡n hoáº·c bá»‹a thÃ´ng tin.
                5. Giá»¯ phong cÃ¡ch tráº£ lá»i thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  nháº¥t quÃ¡n.
                6. Trong context cÃ³ thá»ƒ chá»©a nhiá»u thÃ´ng tin khÃ¡c nhau, hÃ£y táº­p trung vÃ o cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c nháº¥t.

                Nhiá»‡m vá»¥ cá»§a báº¡n:
                - Tráº£ lá»i cÃ¡c cÃ¢u há»i vá» CLB Láº­p trÃ¬nh ProPTIT: lá»‹ch sá»­, thÃ nh viÃªn, hoáº¡t Ä‘á»™ng, sá»± kiá»‡n, dá»± Ã¡n, ná»™i quy, thÃ nh viÃªn tiÃªu biá»ƒu, vÃ  cÃ¡c thÃ´ng tin liÃªn quan khÃ¡c.
                """
            }
        ]
        context = "Content tá»« cÃ¡c tÃ i liá»‡u liÃªn quan:\n"
        context += "\n".join([result["information"] for result in results])

        # ThÃªm context vÃ o messages
        messages.append({
            "role": "user",
            "content": context + "\n\nCÃ¢u há»i: " + query
        })
        # Gá»i API Ä‘á»ƒ láº¥y cÃ¢u tráº£ lá»i
        response = embedding.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages
            )
        response = response.choices[0].message.content.strip()
        scores = rouge.get_scores(response, reply)
        rouge_l = scores[0]['rouge-l']['f']
        total_rouge_l += rouge_l
        time.sleep(5)
    return total_rouge_l / len(df_train) if len(df_train) > 0 else 0

# HÃ m BLEU-4
from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction
def bleu_4_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    total_bleu_4 = 0
    smoothing_function = SmoothingFunction().method1
    initial_top_n = max(10*k, k)
    for index, row in df_train.iterrows():
        query = row['Query']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information", user_embedding, limit=k)
        # rerank
        '''
        cnt = 0
        print("ğŸ“„ Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
        
        for result in results:
            print(f"VÄƒn báº£n sá»‘ {cnt + 1}:")
            print(f"Title: {result['title']}")
            print(f"Information: {result['information']}")
            print("-" * 50)
            cnt += 1
            if(cnt == 5):
                break
        
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)

        reranked_results = reranked_results[:(k+5)]
        
        # In káº¿t quáº£ sau reranking
        print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
            print("-" *50)

        '''
        reply = row['Ground truth answer']
        messages = [
            {
                "role": "system",
                "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn cung cáº¥p thÃ´ng tin vá» CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT.
                Báº¡n sáº½ nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u ngá»¯ cáº£nh (context) tá»« má»™t há»‡ thá»‘ng Retrieval-Augmented Generation (RAG) chá»©a cÃ¡c thÃ´ng tin chÃ­nh xÃ¡c vá» CLB.

                NguyÃªn táº¯c tráº£ lá»i:
                1. Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« context Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ tráº£ lá»i. Context sáº½ Ä‘Æ°á»£c cung cáº¥p á»Ÿ Ä‘áº§u má»—i query cá»§a ngÆ°á»i dÃ¹ng. CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng náº±m á»Ÿ cuá»‘i. 
                2. Náº¿u ngÆ°á»i dÃ¹ng há»i cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n CLB ProPTIT, hÃ£y tráº£ lá»i nhÆ° bÃ¬nh thÆ°á»ng, nhÆ°ng khÃ´ng sá»­ dá»¥ng thÃ´ng tin tá»« context
                3. TrÃ¬nh bÃ y cÃ¢u tráº£ lá»i rÃµ rÃ ng, dá»… hiá»ƒu. CÃ³ thá»ƒ sá»­ dá»¥ng emoij icon khi cáº§n.
                4. Tuyá»‡t Ä‘á»‘i khÃ´ng suy Ä‘oÃ¡n hoáº·c bá»‹a thÃ´ng tin.
                5. Giá»¯ phong cÃ¡ch tráº£ lá»i thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  nháº¥t quÃ¡n.
                6. Trong context cÃ³ thá»ƒ chá»©a nhiá»u thÃ´ng tin khÃ¡c nhau, hÃ£y táº­p trung vÃ o cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c nháº¥t.

                Nhiá»‡m vá»¥ cá»§a báº¡n:
                - Tráº£ lá»i cÃ¡c cÃ¢u há»i vá» CLB Láº­p trÃ¬nh ProPTIT: lá»‹ch sá»­, thÃ nh viÃªn, hoáº¡t Ä‘á»™ng, sá»± kiá»‡n, dá»± Ã¡n, ná»™i quy, thÃ nh viÃªn tiÃªu biá»ƒu, vÃ  cÃ¡c thÃ´ng tin liÃªn quan khÃ¡c.
                """
            }
        ]
        context = "Content tá»« cÃ¡c tÃ i liá»‡u liÃªn quan:\n"
        context += "\n".join([result["information"] for result in results])

        # Sá»­a content náº¿u muá»‘n
        messages.append({
            "role": "user",
            "content": context + "\n\nCÃ¢u há»i: " + query
        })
        # Gá»i  API Ä‘á»ƒ láº¥y cÃ¢u tráº£ lá»i
        response = embedding.client.chat.completions.create(
            model = "gpt-4o-mini",
            messages = messages
        )
        response = response.choices[0].message.content.strip()
        
        reference = reply.split()
        candidate = response.split()
        bleu_4 = sentence_bleu([reference], candidate, smoothing_function=smoothing_function)
        total_bleu_4 += bleu_4
        time.sleep(5)
    return total_bleu_4 / len(df_train) if len(df_train) > 0 else 0

# HÃ m Groundedness (LLM Answer - Hallucination Detection)\

def groundedness_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    total_groundedness = 0
    initial_top_n = max(10*k, k)
    for index, row in df_train.iterrows():
        hits = 0
        cnt = 0
        query = row['Query']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information", user_embedding, limit=k)
        # rerank
        '''
        cnt = 0
        print("ğŸ“„ Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
        
        for result in results:
            print(f"VÄƒn báº£n sá»‘ {cnt + 1}:")
            print(f"Title: {result['title']}")
            print(f"Information: {result['information']}")
            print("-" * 50)
            cnt += 1
            if(cnt == 5):
                break
        
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)

        reranked_results = reranked_results[:k]
        
        # In káº¿t quáº£ sau reranking
        print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
            print("-" *50)

        '''
        reply = row['Ground truth answer']
        messages = [
            {
                "role": "system",
                "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn cung cáº¥p thÃ´ng tin vá» CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT.
                Báº¡n sáº½ nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u ngá»¯ cáº£nh (context) tá»« má»™t há»‡ thá»‘ng Retrieval-Augmented Generation (RAG) chá»©a cÃ¡c thÃ´ng tin chÃ­nh xÃ¡c vá» CLB.

                NguyÃªn táº¯c tráº£ lá»i:
                1. Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« context Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ tráº£ lá»i. Context sáº½ Ä‘Æ°á»£c cung cáº¥p á»Ÿ Ä‘áº§u má»—i query cá»§a ngÆ°á»i dÃ¹ng. CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng náº±m á»Ÿ cuá»‘i. 
                2. Náº¿u ngÆ°á»i dÃ¹ng há»i cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n CLB ProPTIT, hÃ£y tráº£ lá»i nhÆ° bÃ¬nh thÆ°á»ng, nhÆ°ng khÃ´ng sá»­ dá»¥ng thÃ´ng tin tá»« context
                3. TrÃ¬nh bÃ y cÃ¢u tráº£ lá»i rÃµ rÃ ng, dá»… hiá»ƒu. CÃ³ thá»ƒ sá»­ dá»¥ng emoij icon khi cáº§n.
                4. Tuyá»‡t Ä‘á»‘i khÃ´ng suy Ä‘oÃ¡n hoáº·c bá»‹a thÃ´ng tin.
                5. Giá»¯ phong cÃ¡ch tráº£ lá»i thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  nháº¥t quÃ¡n.
                6. Trong context cÃ³ thá»ƒ chá»©a nhiá»u thÃ´ng tin khÃ¡c nhau, hÃ£y táº­p trung vÃ o cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c nháº¥t.

                Nhiá»‡m vá»¥ cá»§a báº¡n:
                - Tráº£ lá»i cÃ¡c cÃ¢u há»i vá» CLB Láº­p trÃ¬nh ProPTIT: lá»‹ch sá»­, thÃ nh viÃªn, hoáº¡t Ä‘á»™ng, sá»± kiá»‡n, dá»± Ã¡n, ná»™i quy, thÃ nh viÃªn tiÃªu biá»ƒu, vÃ  cÃ¡c thÃ´ng tin liÃªn quan khÃ¡c.
                """
            }
        ]
        context = "Content tá»« cÃ¡c tÃ i liá»‡u liÃªn quan:\n"
        context += "\n".join([result["information"] for result in results])

        # ThÃªm context vÃ o messages, sá»­a content náº¿u muá»‘n
        messages.append({
            "role": "user",
            "content": context + "\n\nCÃ¢u há»i: " + query
        })
        # Gá»i  API Ä‘á»ƒ láº¥y cÃ¢u tráº£ lá»i
        response = embedding.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages
            )
        response = response.choices[0].message.content.strip()
        
    
        # TÃ¡ch response thÃ nh cÃ¡c cÃ¢u
        sentences = response.split('. ')
        for sentence in sentences:
            # Táº¡o má»™t prompt Ä‘á»ƒ kiá»ƒm tra tÃ­nh groundedness cá»§a cÃ¢u
            # NOTE: CÃ¡c em cÃ³ thá»ƒ sá»­a Ä‘á»•i prompt nÃ y náº¿u muá»‘n
            messages_groundedness = [
                {
                    "role": "system",
                    "content": """Báº¡n lÃ  má»™t chuyÃªn gia Ä‘Ã¡nh giÃ¡ Groundedness trong há»‡ thá»‘ng RAG, cÃ³ nhiá»‡m vá»¥ phÃ¢n loáº¡i tá»«ng cÃ¢u cá»§a cÃ¢u tráº£ lá»i dá»±a trÃªn ngá»¯ cáº£nh Ä‘Ã£ cho.
                    Báº¡n sáº½ Ä‘Æ°á»£c cung cáº¥p má»™t ngá»¯ cáº£nh, má»™t cÃ¢u há»i vÃ  má»™t cÃ¢u trong pháº§n tráº£ lá»i tá»« mÃ´ hÃ¬nh AI. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘Ã¡nh giÃ¡ cÃ¢u tráº£ lá»i Ä‘Ã³ dá»±a trÃªn ngá»¯ cáº£nh vÃ  cÃ¢u há»i.
                    Input:
                    Question: CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
                    Contexts: Má»™t hoáº·c nhiá»u Ä‘oáº¡n vÄƒn báº£n Ä‘Æ°á»£c truy xuáº¥t
                    Answer: Chá»‰ má»™t cÃ¢u trong Ä‘oáº¡n vÄƒn báº£n LLM sinh ra
                    Báº¡n hÃ£y Ä‘Ã¡nh giÃ¡ dá»±a trÃªn cÃ¡c nhÃ£n sau: 
                    supported: Ná»™i dung cÃ¢u Ä‘Æ°á»£c ngá»¯ cáº£nh há»— trá»£ hoáº·c suy ra trá»±c tiáº¿p.
                    unsupported: Ná»™i dung cÃ¢u khÃ´ng Ä‘Æ°á»£c ngá»¯ cáº£nh há»— trá»£, vÃ  khÃ´ng thá»ƒ suy ra tá»« Ä‘Ã³.
                    contradictory: Ná»™i dung cÃ¢u trÃ¡i ngÆ°á»£c hoáº·c mÃ¢u thuáº«n vá»›i ngá»¯ cáº£nh.
                    no_rad: CÃ¢u khÃ´ng yÃªu cáº§u kiá»ƒm tra thá»±c táº¿ (vÃ­ dá»¥: cÃ¢u chÃ o há»i, Ã½ kiáº¿n cÃ¡ nhÃ¢n, cÃ¢u há»i tu tá»«, disclaimers).
                    HÃ£y tráº£ lá»i báº±ng má»™t trong cÃ¡c nhÃ£n trÃªn, khÃ´ng giáº£i thÃ­ch gÃ¬ thÃªm. Chá»‰ tráº£ lá»i má»™t tá»« duy nháº¥t lÃ  nhÃ£n Ä‘Ã³.
                    VÃ­ dá»¥:
                    Question: Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t vá» lá»‹ch sá»­ cá»§a CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT khÃ´ng?
                    Contexts: CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT Ä‘Æ°á»£c ra Ä‘á»i vÃ o nÄƒm 2011, vá»›i má»¥c tiÃªu táº¡o ra má»™t mÃ´i trÆ°á»ng há»c táº­p vÃ  giao lÆ°u cho cÃ¡c sinh viÃªn Ä‘am mÃª láº­p trÃ¬nh.
                    Answer: CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT Ä‘Æ°á»£c thÃ nh láº­p vÃ o nÄƒm 2011.
                    supported"""
                }
            ]
            # Sá»­a content náº¿u muá»‘n
            messages_groundedness.append({
                "role": "user",
                "content": f"Question: {query}\n\nContexts: {context}\n\nAnswer: {sentence.strip()}"
            })
            # Gá»i  API Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ groundedness
            groundedness_response = embedding.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages_groundedness
            )
            groundedness_reply = groundedness_response.choices[0].message.content.strip()

            if groundedness_reply == "supported":
                hits += 1
                cnt += 1
            elif groundedness_reply == "unsupported" or groundedness_reply == "contradictory":
                cnt += 1
        total_groundedness += hits / cnt if cnt > 0 else 0
        time.sleep(5)
    return total_groundedness / len(df_train) if len(df_train) > 0 else 0 

# HÃ m Response Relevancy (LLM Answer - Measures relevance)


def generate_related_questions(response, embedding):
    # Sá»­a systemp prompt náº¿u muá»‘n
    messages_related = [
        {
            "role": "system",
            "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn táº¡o ra cÃ¡c cÃ¢u há»i liÃªn quan tá»« má»™t cÃ¢u tráº£ lá»i. Báº¡n sáº½ Ä‘Æ°á»£c cung cáº¥p má»™t cÃ¢u tráº£ lá»i vÃ  nhiá»‡m vá»¥ cá»§a báº¡n lÃ  táº¡o ra cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n cÃ¢u tráº£ lá»i Ä‘Ã³. 
            Quy táº¯c:
            1. HÃ£y táº¡o ra Ã­t nháº¥t 5 cÃ¢u há»i liÃªn quan, má»—i cÃ¢u há»i nÃªn ngáº¯n gá»n, rÃµ rÃ ng vÃ  cÃ³ thá»ƒ tÆ°Æ¡ng Ä‘á»“ng nhau.
            2. Chá»‰ dá»±a trÃªn thÃ´ng tin chÃ­nh cÃ³ trong cÃ¢u tráº£ lá»i Ä‘Æ°á»£c cung cáº¥p.
            3. Tráº£ lá»i dÆ°á»›i dáº¡ng list cÃ¡c cÃ¢u há»i nhÆ° á»Ÿ vÃ­ dá»¥ dÆ°á»›i. LÆ¯U Ã: Tráº£ lá»i dÆ°á»›i dáº¡ng ["cÃ¢u há»i 1", "cÃ¢u há»i 2", "cÃ¢u há»i 3", ...], bao gá»“m cáº£ dáº¥u ngoáº·c vuÃ´ng.
            VÃ­ dá»¥:
            CÃ¢u tráº£ lá»i: CÃ¢u láº¡c bá»™ Láº­p TrÃ¬nh PTIT (Programming PTIT), tÃªn viáº¿t táº¯t lÃ  PROPTIT Ä‘Æ°á»£c thÃ nh láº­p ngÃ y 9/10/2011. Vá»›i phÆ°Æ¡ng chÃ¢m hoáº¡t Ä‘á»™ng "Chia sáº» Ä‘á»ƒ cÃ¹ng nhau phÃ¡t triá»ƒn", cÃ¢u láº¡c bá»™ lÃ  nÆ¡i giao lÆ°u, Ä‘Ã o táº¡o cÃ¡c mÃ´n láº­p trÃ¬nh vÃ  cÃ¡c mÃ´n há»c trong trÆ°á»ng, táº¡o Ä‘iá»u kiá»‡n Ä‘á»ƒ sinh viÃªn trong Há»c viá»‡n cÃ³ mÃ´i trÆ°á»ng há»c táº­p nÄƒng Ä‘á»™ng sÃ¡ng táº¡o. Slogan: Láº­p TrÃ¬nh PTIT - Láº­p trÃ¬nh tá»« trÃ¡i tim.
            Output cá»§a báº¡n: "["ThÃ´ng tin cá»¥ thá»ƒ vá» CLB lÃ  gÃ¬?", "CLB Láº­p TrÃ¬nh PTIT Ä‘Æ°á»£c thÃ nh láº­p khi nÃ o?", "Slogan cá»§a CLB lÃ  gÃ¬?", "Má»¥c tiÃªu cá»§a CLB lÃ  gÃ¬?"]"
            CÃ¢u tráº£ lá»i: Náº¿u báº¡n thuá»™c ngÃ nh khÃ¡c báº¡n váº«n cÃ³ thá»ƒ tham gia CLB chÃºng mÃ¬nh. Náº¿u Ä‘á»‹nh hÆ°á»›ng cá»§a báº¡n hoÃ n toÃ n lÃ  theo CNTT thÃ¬ CLB cháº¯c cháº¯n lÃ  nÆ¡i phÃ¹ há»£p nháº¥t Ä‘á»ƒ cÃ¡c báº¡n phÃ¡t triá»ƒn. Trá»Ÿ ngáº¡i lá»›n nháº¥t sáº½ lÃ  do báº¡n theo má»™t hÆ°á»›ng khÃ¡c ná»¯a nÃªn sáº½ pháº£i táº­p trung vÃ o cáº£ 2 máº£ng nÃªn sáº½ cáº§n cá»‘ gáº¯ng nhiá»u hÆ¡n.
            Output cá»§a báº¡n: "["NgÃ nh nÃ o cÃ³ thá»ƒ tham gia CLB?", "CLB phÃ¹ há»£p vá»›i nhá»¯ng ai?", "Há»c ngÃ nh khÃ¡c cÃ³ Ä‘Æ°á»£c tham gia CLB khÃ´ng?"]
            """
            
        },
        {
            "role": "developer",
            "content": """
            Quy trÃ¬nh táº¡o cÃ¢u há»i:
            1. TrÃ­ch cÃ¡c Ã½/ thuáº­t ngá»¯/ Ä‘á»‘i tÆ°á»£ng chÃ­nh trong cÃ¢u tráº£ lá»i Ä‘Æ°á»£c cung cáº¥p.
            2. Sinh cÃ¢u há»i dáº¡ng who/what/when/where/how/why xoay quanh cÃ¡c Ã½ Ä‘Ã³.
            3. Æ¯u tiÃªn cÃ¢u há»i cÃ³ thá»ƒ tráº£ lá»i trá»±c tiáº¿p tá»« vÄƒn báº£n gá»‘c.
            4. Loáº¡i bá» cÃ¢u há»i mÆ¡ há»“ hoáº·c Ä‘Æ°a thÃ´ng tin má»›i khÃ´ng cÃ³ trong vÄƒn báº£n tráº£ lá»i.
            """
        }
    ]
    # Sá»­a content náº¿u muá»‘n
    messages_related.append({
        "role": "user",
        "content": f"CÃ¢u tráº£ lá»i: {response}"
    })
    # Gá»i  API Ä‘á»ƒ táº¡o ra cÃ¡c cÃ¢u há»i liÃªn quan
    related_response = embedding.client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages_related
    )
    related_questions = related_response.choices[0].message.content.strip()
    return related_questions

def response_relevancy_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    total_relevancy = 0
    initial_top_n = max(10*k, k)
    for index, row in df_train.iterrows():
        hits = 0
        cnt = 0
        query = row['Query']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information", user_embedding, limit=initial_top_n)
        # rerank
        cnt = 0
        '''
        print("ğŸ“„ Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
        
        for result in results:
            print(f"VÄƒn báº£n sá»‘ {cnt + 1}:")
            print(f"Title: {result['title']}")
            print(f"Information: {result['information']}")
            print("-" * 50)
            cnt += 1
            if(cnt == 5):
                break
        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)

        reranked_results = reranked_results[:(k + 5)]
        '''
        # In káº¿t quáº£ sau reranking
        dem = 0
        print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
            print("-" *50)
            dem += 1
            if dem == 5:
                break

        '''
        reply = row['Ground truth answer']
        messages = [
            {
                "role": "system",
                "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn cung cáº¥p thÃ´ng tin vá» CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT.
                Báº¡n sáº½ nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u ngá»¯ cáº£nh (context) tá»« má»™t há»‡ thá»‘ng Retrieval-Augmented Generation (RAG) chá»©a cÃ¡c thÃ´ng tin chÃ­nh xÃ¡c vá» CLB.

                NguyÃªn táº¯c tráº£ lá»i:
                1. Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« context Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ tráº£ lá»i. Context sáº½ Ä‘Æ°á»£c cung cáº¥p á»Ÿ Ä‘áº§u má»—i query cá»§a ngÆ°á»i dÃ¹ng. CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng náº±m á»Ÿ cuá»‘i. 
                2. Náº¿u ngÆ°á»i dÃ¹ng há»i cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n CLB ProPTIT, hÃ£y tráº£ lá»i nhÆ° bÃ¬nh thÆ°á»ng, nhÆ°ng khÃ´ng sá»­ dá»¥ng thÃ´ng tin tá»« context
                3. TrÃ¬nh bÃ y cÃ¢u tráº£ lá»i rÃµ rÃ ng, dá»… hiá»ƒu. CÃ³ thá»ƒ sá»­ dá»¥ng emoij icon khi cáº§n.
                4. Tuyá»‡t Ä‘á»‘i khÃ´ng suy Ä‘oÃ¡n hoáº·c bá»‹a thÃ´ng tin.
                5. Giá»¯ phong cÃ¡ch tráº£ lá»i thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  nháº¥t quÃ¡n.
                6. Trong context cÃ³ thá»ƒ chá»©a nhiá»u thÃ´ng tin khÃ¡c nhau, hÃ£y táº­p trung vÃ o cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c nháº¥t.

                Nhiá»‡m vá»¥ cá»§a báº¡n:
                - Tráº£ lá»i cÃ¡c cÃ¢u há»i vá» CLB Láº­p trÃ¬nh ProPTIT: lá»‹ch sá»­, thÃ nh viÃªn, hoáº¡t Ä‘á»™ng, sá»± kiá»‡n, dá»± Ã¡n, ná»™i quy, thÃ nh viÃªn tiÃªu biá»ƒu, vÃ  cÃ¡c thÃ´ng tin liÃªn quan khÃ¡c.
                """
            }
        ]
        context = "Content tá»« cÃ¡c tÃ i liá»‡u liÃªn quan:\n"
        context += "\n".join([result["information"] for result in reranked_results])
        # Sá»­a content náº¿u muá»‘n
        messages.append({
            "role": "user",
            "content": context + "\n\nCÃ¢u há»i: " + query
        })
        # Gá»i  API Ä‘á»ƒ láº¥y cÃ¢u tráº£ lá»i
        response = embedding.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages
            )
        response = response.choices[0].message.content.strip()
       

        # DÃ¹ng cÃ¢u tráº£ lá»i cá»§a LLM Ä‘á»ƒ sinh ra cÃ¡c cÃ¢u há»i liÃªn quan
        related_questions = generate_related_questions(response, embedding) # "["CLB Láº­p TrÃ¬nh PTIT Ä‘Æ°á»£c thÃ nh láº­p khi nÃ o?", "Slogan cá»§a CLB lÃ  gÃ¬?", "Má»¥c tiÃªu cá»§a CLB lÃ  gÃ¬?"]"
       
        related_questions = eval(related_questions) if related_questions else []  # Chuyá»ƒn Ä‘á»•i chuá»—i thÃ nh danh sÃ¡ch
        for question in related_questions:
            question_embedding = embedding.encode(question)
            # TÃ­nh score relevancy giá»¯a cÃ¢u há»i vÃ  query
            score = similarity(user_embedding, question_embedding)
            hits += score
        total_relevancy += hits / len(related_questions) if len(related_questions) > 0 else 0
        time.sleep(5)
    return total_relevancy / len(df_train) if len(df_train) > 0 else 0


# HÃ m Noise Sensitivity (LLM Answer - Robustness to Hallucination)

def noise_sensitivity_k(file_clb_proptit, file_train, embedding, vector_db, k=5):
    df_clb = pd.read_csv(file_clb_proptit)
    df_train = pd.read_excel(file_train)

    total_sensitivity = 0
    initial_top_n = max(10*k,k)
    for index, row in df_train.iterrows():
        hits = 0
        cnt = 0
        query = row['Query']
        # Táº¡o embedding cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
        user_embedding = embedding.encode(query)

        # TÃ¬m kiáº¿m thÃ´ng tin liÃªn quan trong cÆ¡ sá»Ÿ dá»¯ liá»‡u
        results = vector_db.query("information", user_embedding, limit=initial_top_n)
        # rerank
        '''
        cnt = 0
        print("ğŸ“„ Káº¿t quáº£ tÃ¬m kiáº¿m trÆ°á»›c khi rerank:")
        
        for result in results:
            print(f"VÄƒn báº£n sá»‘ {cnt + 1}:")
            print(f"Title: {result['title']}")
            print(f"Information: {result['information']}")
            print("-" * 50)
            cnt += 1
            if(cnt == 5):
                break
        '''
        passages = [result["information"] for result in results]
        scores, reranker_passages = reranker(query, passages)

        # (5) Map ngÆ°á»£c passage -> result gá»‘c Ä‘á»ƒ khÃ´ng máº¥t title/metadata
        #    DÃ¹ng dict {passage: [list cÃ¡c index]} Ä‘á»ƒ xá»­ lÃ½ trÆ°á»ng há»£p passage trÃ¹ng nhau
        passage2idxs = defaultdict(list)
        for idx, p in enumerate(passages):
            passage2idxs[p].append(idx)

        reranked_results = []
        for s, p in zip(scores,  reranker_passages):
            if passage2idxs[p]:
                idx = passage2idxs[p].pop(0)   # láº¥y index Ä‘áº§u tiÃªn khá»›p passage nÃ y
                r = results[idx].copy()        # copy Ä‘á»ƒ khÃ´ng sá»­a object gá»‘c (tuá»³ báº¡n)
                r["_rerank_score"] = float(s)
                reranked_results.append(r)

        reranked_results = reranked_results[:(k + 5)]

        # In káº¿t quáº£ sau reranking
        '''   
        dem = 0
        print("\nğŸ“Š Káº¿t quáº£ sau khi rerank:")
        for i, r in enumerate (reranked_results):
            print(f"VÄƒn báº£n{i+1} | Score: {r.get('_rerank_score', 0):.4f}")
            print(r.get('information', ''))
            print("-" *50)
            dem += 1
            if dem == 5:
                break
        '''


        reply = row['Ground truth answer']
        messages = [
            {
                "role": "system",
                "content": """Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn cung cáº¥p thÃ´ng tin vá» CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT.
                Báº¡n sáº½ nháº­n Ä‘Æ°á»£c dá»¯ liá»‡u ngá»¯ cáº£nh (context) tá»« má»™t há»‡ thá»‘ng Retrieval-Augmented Generation (RAG) chá»©a cÃ¡c thÃ´ng tin chÃ­nh xÃ¡c vá» CLB.

                NguyÃªn táº¯c tráº£ lá»i:
                1. Chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« context Ä‘Æ°á»£c cung cáº¥p Ä‘á»ƒ tráº£ lá»i. Context sáº½ Ä‘Æ°á»£c cung cáº¥p á»Ÿ Ä‘áº§u má»—i query cá»§a ngÆ°á»i dÃ¹ng. CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng náº±m á»Ÿ cuá»‘i. 
                2. Náº¿u ngÆ°á»i dÃ¹ng há»i cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n CLB ProPTIT, hÃ£y tráº£ lá»i nhÆ° bÃ¬nh thÆ°á»ng, nhÆ°ng khÃ´ng sá»­ dá»¥ng thÃ´ng tin tá»« context
                3. TrÃ¬nh bÃ y cÃ¢u tráº£ lá»i rÃµ rÃ ng, dá»… hiá»ƒu. CÃ³ thá»ƒ sá»­ dá»¥ng emoij icon khi cáº§n.
                4. Tuyá»‡t Ä‘á»‘i khÃ´ng suy Ä‘oÃ¡n hoáº·c bá»‹a thÃ´ng tin.
                5. Giá»¯ phong cÃ¡ch tráº£ lá»i thÃ¢n thiá»‡n, chuyÃªn nghiá»‡p vÃ  nháº¥t quÃ¡n.
                6. Trong context cÃ³ thá»ƒ chá»©a nhiá»u thÃ´ng tin khÃ¡c nhau, hÃ£y táº­p trung vÃ o cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ tráº£ lá»i chÃ­nh xÃ¡c nháº¥t.

                Nhiá»‡m vá»¥ cá»§a báº¡n:
                - Tráº£ lá»i cÃ¡c cÃ¢u há»i vá» CLB Láº­p trÃ¬nh ProPTIT: lá»‹ch sá»­, thÃ nh viÃªn, hoáº¡t Ä‘á»™ng, sá»± kiá»‡n, dá»± Ã¡n, ná»™i quy, thÃ nh viÃªn tiÃªu biá»ƒu, vÃ  cÃ¡c thÃ´ng tin liÃªn quan khÃ¡c.
                """
            }
        ]
        context =  context = "Content tá»« cÃ¡c tÃ i liá»‡u liÃªn quan:\n"
        context += "\n".join([result["information"] for result in reranked_results])

        # ThÃªm context vÃ o messages, sá»­a content náº¿u muá»‘n
        messages.append({
            "role": "user",
            "content": context + "\n\nCÃ¢u há»i: " + query
        })
        # Gá»i  API Ä‘á»ƒ láº¥y cÃ¢u tráº£ lá»i
        response = embedding.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages
            )
        response = response.choices[0].message.content.strip()

        sentences = response.split('. ')
        for sentence in sentences:
            # Sá»­a prompt náº¿u muá»‘n
            messages_sensitivity = [
                {
                    "role": "system",
                    "content": """Báº¡n lÃ  má»™t chuyÃªn gia Ä‘Ã¡nh giÃ¡ Ä‘á»™ nháº¡y cáº£m cá»§a cÃ¢u tráº£ lá»i trong há»‡ thá»‘ng RAG, cÃ³ nhiá»‡m vá»¥ phÃ¢n loáº¡i tá»«ng cÃ¢u cá»§a cÃ¢u tráº£ lá»i dá»±a trÃªn ngá»¯ cáº£nh Ä‘Ã£ cho.
                    Báº¡n sáº½ Ä‘Æ°á»£c cung cáº¥p má»™t ngá»¯ cáº£nh, má»™t cÃ¢u há»i vÃ  má»™t cÃ¢u trong pháº§n tráº£ lá»i tá»« mÃ´ hÃ¬nh AI. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘Ã¡nh giÃ¡ cÃ¢u tráº£ lá»i Ä‘Ã³ dá»±a trÃªn ngá»¯ cáº£nh vÃ  cÃ¢u há»i.
                    Input:
                    Question: CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng
                    Contexts: Má»™t hoáº·c nhiá»u Ä‘oáº¡n vÄƒn báº£n Ä‘Æ°á»£c truy xuáº¥t
                    Answer: Chá»‰ má»™t cÃ¢u trong Ä‘oáº¡n vÄƒn báº£n LLM sinh ra
                    Báº¡n hÃ£y Ä‘Ã¡nh giÃ¡ dá»±a trÃªn cÃ¡c nhÃ£n sau: 
                    1: Ná»™i dung cÃ¢u Ä‘Æ°á»£c ngá»¯ cáº£nh há»— trá»£ hoáº·c suy ra trá»±c tiáº¿p.
                    0: Ná»™i dung cÃ¢u khÃ´ng Ä‘Æ°á»£c ngá»¯ cáº£nh há»— trá»£, vÃ  khÃ´ng thá»ƒ suy ra tá»« Ä‘Ã³.
                    VÃ­ dá»¥:
                    Question: Báº¡n cÃ³ thá»ƒ cho tÃ´i biáº¿t vá» lá»‹ch sá»­ cá»§a CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT khÃ´ng?
                    Contexts: CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT Ä‘Æ°á»£c ra Ä‘á»i vÃ o nÄƒm 2011, vá»›i má»¥c tiÃªu táº¡o ra má»™t mÃ´i trÆ°á»ng há»c táº­p vÃ  giao lÆ°u cho cÃ¡c sinh viÃªn Ä‘am mÃª láº­p trÃ¬nh.
                    Answer: CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT Ä‘Æ°á»£c thÃ nh láº­p vÃ o nÄƒm 2011.
                    1
                    Question: CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT Ä‘Æ°á»£c thÃ nh láº­p vÃ o nÄƒm 2011. Báº¡n cÃ³ biáº¿t ngÃ y cá»¥ thá»ƒ khÃ´ng?
                    Contexts: CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT Ä‘Æ°á»£c ra Ä‘á»i vÃ o nÄƒm 2011, vá»›i má»¥c tiÃªu táº¡o ra má»™t mÃ´i trÆ°á»ng há»c táº­p vÃ  giao lÆ°u cho cÃ¡c sinh viÃªn Ä‘am mÃª láº­p trÃ¬nh.
                    Answer: CÃ¢u láº¡c bá»™ Láº­p trÃ¬nh ProPTIT lÃ  CLB thuá»™c PTIT.
                    0"""
                }
            ]
            # Sá»­a prompt náº¿u muá»‘n
            messages_sensitivity.append({
                "role": "user",
                "content": f"Question: {query}\n\nContexts: {context}\n\nAnswer: {sentence.strip()}"
            })
            # Gá»i  API Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ nháº¡y cáº£m
            sensitivity_response = embedding.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages_sensitivity
            )
            sensitivity_reply = sensitivity_response.choices[0].message.content.strip()
            sensitivity_reply = sensitivity_response.choices[0].message.content.strip()
            if sensitivity_reply == "0":
                hits += 1
        total_sensitivity += hits / len(sentences) if len(sentences) > 0 else 0
        time.sleep(3)
    return total_sensitivity / len(df_train) if len(df_train) > 0 else 0


# HÃ m Ä‘á»ƒ tÃ­nh toÃ¡n toÃ n bá»™ metrics trong module LLM Answer

def calculate_metrics_llm_answer(file_clb_proptit, file_train, embedding, vector_db, train):
    # Táº¡o ra 1 báº£ng csv, cá»™t thá»© nháº¥t lÃ  K value, cÃ¡c cá»™t cÃ²n láº¡i lÃ  metrics. Sáº½ cÃ³ 3 hÃ ng tÆ°Æ¡ng trÆ°ng vá»›i k = 3, 5, 7
    k_values = [3, 5, 7]
    metrics = {
        "K": [],
        "string_presence@k": [],
        "rouge_l@k": [],
        "bleu_4@k": [],
        "groundedness@k": [],
        "response_relevancy@k": [],
        "noise_sensitivity@k": []
    }
    # LÆ°u 2 chá»¯ sá»‘ tháº­p phÃ¢n cho cÃ¡c metrics
    for k in k_values:
        metrics["K"].append(k)
        metrics["string_presence@k"].append(round(string_presence_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["rouge_l@k"].append(round(rouge_l_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["bleu_4@k"].append(round(bleu_4_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["groundedness@k"].append(round(groundedness_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["response_relevancy@k"].append(round(response_relevancy_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
        metrics["noise_sensitivity@k"].append(round(noise_sensitivity_k(file_clb_proptit, file_train, embedding, vector_db, k), 2))
    # Chuyá»ƒn Ä‘á»•i metrics thÃ nh DataFrame
    metrics_df = pd.DataFrame(metrics)
    # LÆ°u DataFrame vÃ o file csv
    if train:
        metrics_df.to_csv("metrics_llm_answer_train.csv", index=False)
    else:
        metrics_df.to_csv("metrics_llm_answer_test.csv", index=False)
    return metrics_df

